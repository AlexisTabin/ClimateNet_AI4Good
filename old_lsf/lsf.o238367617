Running on euler with following parameters : 
User : atabin
Model : unet
Data folder : /cluster/work/igp_psr/ai4good/group-1b/data/
Saving directory : /cluster/scratch/atabin/unet/
Checkpoint path : /cluster/scratch/atabin/checkpoints/unet/
  0%|          | 0/80 [00:00<?, ?it/s]{'model': 'unet', 'data_dir': '/cluster/work/igp_psr/ai4good/group-1b/data/', 'checkpoint_path': '/cluster/scratch/atabin/checkpoints/unet/', 'save_dir': '/cluster/scratch/atabin/unet/'}
Running unet...
train_path :  /cluster/work/igp_psr/ai4good/group-1b/data/train/
val_path :  /cluster/work/igp_psr/ai4good/group-1b/data/val/
inference_path :  /cluster/work/igp_psr/ai4good/group-1b/data/test/
Loading data...
Epoch 1:
  0%|          | 0/80 [00:09<?, ?it/s]
Traceback (most recent call last):
  File "/cluster/home/atabin/ClimateNet_AI4Good/run.py", line 33, in <module>
    train.run(
  File "/cluster/home/atabin/ClimateNet_AI4Good/climatenet/train.py", line 37, in run
    model.train(train)
  File "/cluster/home/atabin/ClimateNet_AI4Good/climatenet/models/unet/unet.py", line 65, in train
    outputs = torch.softmax(self.network(features), 1)
  File "/cluster/home/atabin/miniconda3/envs/climatenet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/atabin/ClimateNet_AI4Good/climatenet/models/unet/unet.py", line 334, in forward
    x = self.conv7(self.conv6(x))
  File "/cluster/home/atabin/miniconda3/envs/climatenet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/atabin/miniconda3/envs/climatenet/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 345, in forward
    return self.conv2d_forward(input, self.weight)
  File "/cluster/home/atabin/miniconda3/envs/climatenet/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 341, in conv2d_forward
    return F.conv2d(input, weight, self.bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 432.00 MiB (GPU 0; 7.93 GiB total capacity; 7.09 GiB already allocated; 326.62 MiB free; 7.13 GiB reserved in total by PyTorch)
Done!
